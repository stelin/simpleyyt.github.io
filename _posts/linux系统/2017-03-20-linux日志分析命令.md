---
title: 'linux日志分析命令'
layout: post
tags:
  - linux
  - log
category: linux系统
---
日志分析命令一般由两大类组成过滤和统计。grep sed cut通常用于过滤日志，而sort uniq wc awk通常用于分日志。

<!--more-->

# 日志过滤
## grep
一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。

常用命令

 命令 | 功能
---|---
ps -ef \| grep svn | 查找指定进程
ps -ef \| grep -c svn | 查找指定进程个数
cat test.txt \| grep -f test2.tx| 从文件中读取关键词进行搜索
cat test.txt \| grep -nf test2.txt | 从文件中读取关键词进行搜索 且显示行号
grep 'linux' test.txt | 从文件中查找关键词
grep 'linux' test.txt test2.txt | 从多个文件中查找关键词
ps aux \| grep ssh \| grep -v "grep" | grep不显示本身进程
cat test.txt \|grep ^u | 找出已u开头的行内容
cat test.txt \|grep hat$ | 输出以hat结尾的行内容
## sed
sed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法
         
        
常用命令

命令  | 功能
---|---
sed '1d' ab              |删除第一行 
sed '$d' ab               |删除最后一行
sed '1,2d' ab            |删除第一行到第二行
sed '2,$d' ab            |删除第二行到最后一行
sed -n '1p' ab           |显示第一行 
      sed -n '$p' ab            |显示最后一行
     sed -n '1,2p' ab         |显示第一行到第二行
     sed -n '2,$p' ab         |显示第二行到最后一行
     sed '1c Hi' ab                |第一行代替为Hi
     sed 's/要替换的字符串/新的字符串/g' | 每行搜索替换
     sed 's/ruby/bird/g'    |替换ruby为bird

## cut
cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f标志之一。字符串切割命令
- -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定-n 标志。
- -c ：以字符为单位进行分割。
- -d ：自定义分隔符，默认为制表符。
- -f ：与-d一起使用，指定显示哪个区域。
# 数据统计
## sort
sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。

命令 | 功能
---|---
sort -u seq.txt| 输出过程中去掉重复的
 sort -r number.txt | 默认升序，-r就是降序
 sort -n number.txt| 以数值排序，默认是字符串（10比2小
  sort -n -k 2 -t : facebook.txt | 文件数据以“:”分割后，取第二列按数值排序
## uniq
每行数据进行对比删除重复的行
- -c 在输出行前面加上每行在输入文件中出现的次数。
- -d 仅显示重复行。
- -u 仅显示不重复的行。
- 
命令 | 功能
---|---
uniq file file2 | 删除file文件中重复的行并保存在file2
uniq -c > result.txt | 在每行数据前显示，与该行相同数据的行数

## wc
wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出
- -c 统计字节数。
- -l 统计行数。
- -m 统计字符数。这个标志不能与 -c 标志一起使用。


命令 | 功能
---|---
wc test.txt | 查看文件的字节数、字数、行数
cat test.txt \| wc -l | 只显示行数
cat test.txt \| wc -l | 统计当前目录文件数

## awk
#### 脚本基本结构 

```
awk 'BEGIN{ print "start" } pattern{ commands } END{ print "end" }' file
```
 一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如：
 
```
awk 'BEGIN{ i=0 } { i++ } END{ print i }' filename awk "BEGIN{ i=0 } { i++ } END{ print i }" filename
```
#### 工作原理

```
awk 'BEGIN{ commands } pattern{ commands } END{ commands }'
awk 'BEGIN{ commands } { commands } END{ commands }'
```


- 第一步：执行BEGIN{ commands }语句块中的语句； - 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 
- 第三步：当读至输入流末尾时，执行END{ commands }语句块。
 
. BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。
. END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 
. pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。

[awk语法](http://man.linuxde.net/awk)
## 使用列子
统计日志接口平均耗时

```
cat xxx/project/notice.log* 
| grep -F "[notice]" | awk '{print $6, $8}' | sed 's/\[//g' | sed 's/(ms)\]//g' | sed  's/]//g' 
| awk 'BEGIN{n=0;}
{if($2 != "yii"){n=n+1;costs[$2]=costs[$2]+$1;times[$2]=times[$2]+1;}}
END{print n;for(uri in costs){print uri,costs[uri]/times[uri],times[uri];}}' 
| sort -n -t " " -k  2nr | awk '{printf("%-50s %-10d %-10d\n", $1,$2, $3)}'


```
统计每台服务器日志分析接口性能

```
#!/bin/bash

file=$1
hosts="project-hostname 10.100.26.170 10.100.26.27 10.100.26.28"

printf "%-50s %-7s %-7s %-7s\n" uri avg cnt max
for h in $hosts
do
  cmd="cat /xxx/$file | grep -F '[notice]' | cut -d ' ' -f6,8 | sed -r -e 's/\[([0-9]*)\(ms\)\] \[(.*)\]/\1 \2/' | awk -F ' ' '{cost[\$2]+=\$1; cnt[\$2]++; \$1 > max[\$2] && max[\$2]=\$1;} END {for(uri in cost){print uri,cost[uri], cnt[uri], max[uri]}}'"
#  cmd="head -10 xxx/notice.log | grep -F '[notice]' | cut -d ' ' -f6,8 | sed -r -e 's/\[([0-9]*)\(ms\)\] \[(.*)\]/\1 \2/' | awk -F ' ' '{cost[\$2]+=\$1; cnt[\$2]++; \$1 > max[\$2] && max[\$2]=\$1;} END {for(uri in cost){print uri,cost[uri], cnt[uri], max[uri]}}'"
  ssh worker@$h $cmd
done | awk '{cost[$1]+=$2; cnt[$1]+=$3; $4 > max[$1] && max[$1]=$4;} END {for(uri in cost){printf("%-50s %-7d %-7d %-7d\n", uri, cost[uri]/cnt[uri], cnt[uri], max[uri])}}' | sort -k 1
```




